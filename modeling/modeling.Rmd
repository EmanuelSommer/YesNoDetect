---
title: "Modeling"
author: "Emanuel Sommer"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up

## Load Packages
```{r packages, echo=TRUE,results='hide'}
### Load YesNoDetect
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()

### Load additional packages
library(tensorflow)
library(keras)
```

## Get Data
```{r get data, warning=FALSE}
data <- get_current_db()
```

## Verify data
### Plot average boxes
also save these plots to the package s.t. the plots must not be comupted in every session to reduce loading time and memory usage of the server
```{r visualize average boxes}
plot_average_box(data,sel_label = "x")+theme(plot.background = element_blank(),
                                             panel.background = element_blank(),
                                             panel.border = element_rect(color = "black"))
plot_average_box(data, sel_label = "y")+theme(plot.background = element_blank(),
                                             panel.background = element_blank(),
                                             panel.border = element_rect(color = "black"))
average_no_plot <- plot_average_box(data,sel_label = "x")
average_yes_plot <- plot_average_box(data, sel_label = "y")
usethis::use_data(average_no_plot,overwrite = TRUE)
usethis::use_data(average_yes_plot,overwrite = TRUE)
```

### Verify some examples wrt their labels
```{r}
some_random_indices <- sample(seq(data$label),10)
# some_random_indices <- c(425:433) # the not so random way :)
table(data$label[some_random_indices])
for(i in 1:10){
  print(plot_average_box(data[some_random_indices[i],],sel_label = data$label[some_random_indices[i]])+
  labs(title = paste("Label:",data$label[some_random_indices[i]]),
       subtitle = paste("Index:", some_random_indices[i]))+
  theme(plot.background = element_blank(),
        panel.background = element_blank(),
        panel.border = element_rect(color = "black")))
}
```



## Preprocess data
```{r}
# x data
data_x <- data %>%
  select(-label)
dim_data_orig <- dim(data_x)
data_x_array <- as.array(as.matrix(data_x)) %>%
  array_reshape(dim = c(dim_data_orig[1],28,28),order = "C")%>%
  array_reshape(., dim = c(dim(.), 1))

# train test split
# 20 percent test data
set.seed(2)
train_indices <- sample(which(data$label == "y"),size = round(0.8*sum(data$label == "y")))
train_indices <- c(train_indices,
                   sample(which(data$label == "x"),size = round(0.8*sum(data$label == "x"))))

y_train <- data$label[train_indices]
y_test <- data$label[-train_indices]

print("Original distribution of labels:")
table(data$label)/length(data$label)
print("Train distribution of labels:")
table(y_train)/length(y_train)
print("Test distribution, of labels:")
table(y_test)/length(y_test)

y_train_keras <- to_categorical(ifelse(y_train == "y",1,0))
y_test_keras <- to_categorical(ifelse(y_test == "y",1,0))

x_train <- data_x_array[train_indices,,,] %>%
  array_reshape(., dim = c(dim(.), 1))
x_test <- data_x_array[-train_indices,,,] %>%
  array_reshape(., dim = c(dim(.), 1))

print("Dimensions of train and test data are fine:")
dim_data_orig[1] == dim(x_train)[1]+dim(x_test)[1]
```


# The models

## Model 1 Definition

architecture:

* Input: 28*28 boolean matrix
* Layer 1: Convolutional layer, kernel size = 3*3, padding = 0, stride = 1, filters = 32, activation = relu
* Layer 2: Max Pooling layer, kernel size = 2*2, padding = 0, stride = 2
* Layer 3: Convolutional layer, kernel size = 3*3, padding = 0, stride = 1, filters = 64, activation = relu
* Layer 4: Max Pooling layer, kernel size = 2*2, padding = 0, stride = 2
* Layer 5: Convolutional layer, kernel size = 3*3, padding = 0, stride = 1, filters = 64, activation = relu
* Layer 6: Flatten
* Layer 7: Dense layer, units = 128, activation = relu
* Layer 8: Dense layer, units = 2, , activation = softmax

```{r}
# define model
model_1 <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32,
                kernel_size = c(3,3),
                activation = "relu",
                input_shape = c(28,28,1)) %>% # layer 1
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>% # layer 3
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>% # layer 5
  layer_flatten() %>% 
  layer_dense(units = 128, activation = "relu") %>% 
  layer_dense(units = 2, activation = "softmax")

summary(model_1)
```

## Model 2 Definition

architecture:

* Input: 28*28 boolean matrix
* Layer 1: Convolutional layer, kernel size = 5*5, padding = 0, stride = 1, filters = 32, activation = relu
* Layer 2: Max Pooling layer, kernel size = 2*2, padding = 0, stride = 2
* Layer 3: Convolutional layer, kernel size = 5*5, padding = 0, stride = 1, filters = 32, activation = relu
* Layer 4: Max Pooling layer, kernel size = 2*2, padding = 0, stride = 2
* Layer 5: Convolutional layer, kernel size = 4*4, padding = 0, stride = 1, filters = 64, activation = linear
* Layer 6: Flatten
* Layer 7: Dense layer, units = 256, activation = relu
* Layer 8: Dense layer, units = 2, , activation = softmax

```{r}
model_2 <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32,
                kernel_size = c(5,5),
                activation = "relu",
                input_shape = c(28,28,1)) %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 32, kernel_size = c(5,5), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(4,4), activation = "linear") %>%
  layer_flatten() %>% 
  layer_dense(units = 256, activation = "relu") %>% 
  layer_dense(units = 2, activation = "softmax")

summary(model_2)
```

## Model 3 Definition

architecture:

* Input: 28*28 boolean matrix
* Layer 1: Convolutional layer, kernel size = 4*4, padding = 0, stride = 1, filters = 32, activation = relu
* Layer 2: Max Pooling layer, kernel size = 2*2, padding = 0, stride = 2
* Layer 3: Convolutional layer, kernel size = 4*4, padding = 0, stride = 1, filters = 32, activation = relu
* Layer 4: Max Pooling layer, kernel size = 2*2, padding = 0, stride = 2
* Layer 5: Convolutional layer, kernel size = 4*4, padding = 0, stride = 1, filters = 32, activation = relu
* Layer 6: Flatten
* Layer 7: Dense layer, units = 256, activation = relu
* Layer 8: Dense layer, units = 2, , activation = softmax

```{r}
model_3 <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32,
                kernel_size = c(4,4),
                activation = "relu",
                input_shape = c(28,28,1)) %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 32, kernel_size = c(4,4), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
  layer_flatten() %>% 
  layer_dense(units = 256, activation = "relu") %>% 
  layer_dense(units = 2, activation = "softmax")

summary(model_3)
```

## Model Compilation and Fitting
```{r}
# compile
model_1 %>% 
  compile(loss = "binary_crossentropy",
          optimizer = "adam",
          metrics = "accuracy")
model_2 %>% 
  compile(loss = "binary_crossentropy",
          optimizer = "adam",
          metrics = "accuracy")
model_3 %>% 
  compile(loss = "binary_crossentropy",
          optimizer = "adam",
          metrics = "accuracy")
```

```{r}
# fit model
history_model_1 <- model_1 %>%
  fit(
    x = x_train,
    y = y_train_keras,
    batch_size = NULL,
    epochs = 15,
    view_metrics = FALSE,
    validation_sample = 0.2,
    verbose = 1
  )
history_model_2 <- model_2 %>%
  fit(
    x = x_train,
    y = y_train_keras,
    batch_size = NULL,
    epochs = 12,
    view_metrics = FALSE,
    validation_sample = 0.2,
    verbose = 1
  )
history_model_3 <- model_3 %>%
  fit(
    x = x_train,
    y = y_train_keras,
    batch_size = NULL,
    epochs = 20,
    view_metrics = FALSE,
    validation_sample = 0.2,
    verbose = 1
  )

plot(history_model_1)+labs(title = "Model 1")
plot(history_model_2)+labs(title = "Model 2")
plot(history_model_3)+labs(title = "Model 3")

```







# Model valuation

## Performance on test set
```{r}
# evaluate model
print("Model 1:")
evaluate(model_1,x_test,y_test_keras,verbose = 0)
print("Model 2:")
evaluate(model_2,x_test,y_test_keras,verbose = 0)
print("Model 3:")
evaluate(model_3,x_test,y_test_keras,verbose = 0)
```

## Falsely labeled observations
```{r}
### Model 1
# have a look at falsely labeled ones
pred_mod_1_full <- predict_proba(model_1,data_x_array,verbose = 0)
pred_mod_1_full <- apply(pred_mod_1_full, 1, function(x){ifelse(which.max(x) == 2,"y","x")})
print("Accuracy on the whole set:")
mean(pred_mod_1_full == data$label)
print("Number of misclassified in the whole set:")
sum(pred_mod_1_full != data$label)

```

```{r}
### Model 2
# have a look at falsely labeled ones
pred_mod_2_full <- predict_proba(model_2,data_x_array,verbose = 0)
pred_mod_2_full <- apply(pred_mod_2_full, 1, function(x){ifelse(which.max(x) == 2,"y","x")})
print("Accuracy on the whole set:")
mean(pred_mod_2_full == data$label)
print("Number of misclassified in the whole set:")
sum(pred_mod_2_full != data$label)

```

```{r}
### Model 3
# have a look at falsely labeled ones
pred_mod_3_full <- predict_proba(model_3,data_x_array,verbose = 0)
pred_mod_3_full <- apply(pred_mod_3_full, 1, function(x){ifelse(which.max(x) == 2,"y","x")})
print("Accuracy on the whole set:")
mean(pred_mod_3_full == data$label)
print("Number of misclassified in the whole set:")
sum(pred_mod_3_full != data$label)

```

```{r}
#plot falsely labeled ones (helper function)
plot_falsely_labeled <- function(pred_full_vec){
  falsely_labeled <- which(pred_full_vec != data$label)

  for(i in falsely_labeled){
    print(plot_average_box(data[i,],sel_label = data$label[i])+
          labs(title = paste("Label:",data$label[i], " Prediction:",pred_full_vec[i]),
               subtitle = paste("Index:", i))+
          theme(plot.background = element_blank(),
                panel.background = element_blank(),
                panel.border = element_rect(color = "black"))
          )
  }
}

# plots model 1
plot_falsely_labeled(pred_mod_1_full)
```

```{r}
# plots model 2
plot_falsely_labeled(pred_mod_2_full)
```

```{r}
# plots model 3
plot_falsely_labeled(pred_mod_3_full)
```

## Choose current best model:

Model 2



# Save Model

```{r}
save_model_tf(model_2,filepath = "current_cnn")
```

Save important model metrics:
Number of trainable params
test accuracy
size test set (20 percent of the whole)

```{r}
metrics_list <- list(trainable_params = 76450,
                     test_acc = 0.973,
                     size_test_set = length(data$label)-length(train_indices),
                     size_training_data = length(train_indices),
                     loss = "binary crossentropy",
                     optimizer = "adam")
# save(
#   metrics_list,
#   file = "current_cnn_metrics.RData"
# )
# load("current_cnn_metrics.RData")
usethis::use_data(metrics_list,overwrite = TRUE)
```















